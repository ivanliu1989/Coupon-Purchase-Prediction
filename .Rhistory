# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
#load ODBC library
library(RODBC)
odbcDataSources()
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
# #load data
# data <- sqlFetch(cn, 'myTable', colnames=FALSE, rows_at_time=1000)
# #load data
# data <- sqlQuery(cn, "select * from myTable")
# status <- sqlGetResults(cn, as.is = FALSE, errors = TRUE, max = 0, buffsize = 1000000,
#                         nullstring = NA_character_, na.strings = "NA", believeNRows = TRUE, dec = getOption("dec"),
#                         stringsAsFactors = default.stringsAsFactors())
# #read with odbcQuery
# status  <- odbcQuery(cn, "select * from myTable")
# data <- odbcFetchRows(cn, max = 0, buffsize = 10000, nullstring = NA_character_, believeNRows = TRUE)
# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
require(Rserve)
Rserve()
Rserve()
install.packages(c("boot", "gtools", "manipulate"))
head(train)
rm(list = ls()); gc()
require(data.table);require(caret);require(doMC);require(ROCR)
registerDoMC(core=3)
load('data/new/cv_data_log_extend.RData')
install.packages("manipulate")
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
ound(cor(iris[,1:4]), 2)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
pc
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3])#, col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
plot3d(pc$scores[,1:3], col=iris$Species, main="actual species")
with(iris, table(cluster, Species))
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
setwd('/Users/ivanliu/Downloads/kaggle/Coupon-Purchase-Prediction')
rm(list=ls());gc()
load('../data/2_model_based_train_test_drop_new.RData')
### split train-validation
library(caret)
set.seed(888)
inTraining <- createDataPartition(train$PURCHASE_FLG, p = .75, list = FALSE)
validation <- train[-inTraining,]
training <- train[inTraining,]
dim(validation);dim(training)
object.size(training)/1024/1024/1024
rm(test,train, inTraining, dropout, newregister)
training$PURCHASE_FLG <- as.factor(training$PURCHASE_FLG)
levels(training$PURCHASE_FLG) <- c('No','Yes')
# model settings
fitControl <- trainControl(method = "none", # adaptive_cv
number = 10, #10
#                            repeats = 1, #5
classProbs = TRUE,
summaryFunction = twoClassSummary,
# allowParallel = TRUE,
selectionFunction = 'best'#,
#                            adaptive = list(min = 4, #10
#                                            alpha = 0.05,
#                                            method = "BT",
#                                            complete = TRUE)
)
# grid
Grid <-  expand.grid(interaction.depth = 6,
n.trees = 300,
shrinkage = 0.01#,
#n.minobsinnode = 20
)
# Grid <- expand.grid(mtry = 17)
# train
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "gbm",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
# tuneLength = 6, #8
verbose = TRUE,
tuneGrid = Grid,
metric = "ROC")
fit
featImp <- varImp(fit, scale = FALSE)
featImp
ggplot(fit)
pred <- predict(fit, newdata = validation, type = "prob")
head(pred)
range(pred$Yes)
gbmFit <- fit
object.size(fit)
object.size(fit)/1024/1024/1024
save(gbmFit, file='../trained_models.RData')
setwd('/Users/ivanliu/Downloads/kaggle/Coupon-Purchase-Prediction')
rm(list=ls());gc()
load('../data/2_model_based_train_test_drop_new.RData')
### split train-validation
library(caret)
set.seed(888)
inTraining <- createDataPartition(train$PURCHASE_FLG, p = .75, list = FALSE)
validation <- train[-inTraining,]
training <- train[inTraining,]
dim(validation);dim(training)
object.size(training)/1024/1024/1024
rm(test,train, inTraining, dropout, newregister)
### modeling
# library(doMC)
# registerDoMC(cores = 2)
training$PURCHASE_FLG <- as.factor(training$PURCHASE_FLG)
levels(training$PURCHASE_FLG) <- c('No','Yes')
# model settings
fitControl <- trainControl(method = "none", # adaptive_cv
number = 10, #10
#                            repeats = 1, #5
classProbs = TRUE,
summaryFunction = twoClassSummary,
# allowParallel = TRUE,
selectionFunction = 'best'#,
#                            adaptive = list(min = 4, #10
#                                            alpha = 0.05,
#                                            method = "BT",
#                                            complete = TRUE)
)
# grid
# Grid <-  expand.grid(interaction.depth = 6,
#                      n.trees = 300,
#                      shrinkage = 0.01#,
#                      #n.minobsinnode = 20
# )
# Grid <- expand.grid(mtry = 17) #rf
Grid <- expand.grid(size = 9, decay = 0.5) #nnet
# Grid <- expand.grid(fL = 3, usekernel = 0.9) #nb
# Grid <- expand.grid(nlter) #LogitBoost
# train
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "nnet",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
# tuneLength = 6, #8
verbose = TRUE,
tuneGrid = Grid,
metric = "ROC")
Grid <- expand.grid(size = 6, decay = 0.5) #nnet
# Grid <- expand.grid(fL = 3, usekernel = 0.9) #nb
# Grid <- expand.grid(nlter) #LogitBoost
# train
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "nnet",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
# tuneLength = 6, #8
verbose = TRUE,
tuneGrid = Grid,
metric = "ROC")
fit
featImp <- varImp(fit, scale = FALSE)
featImp
ggplot(fit)
pred <- predict(fit, newdata = validation, type = "prob")
head(pred)
range(pred$Yes)
head(pred, 50)
head(validation$PURCHASE_FLG, 50)
head(validation$PURCHASE_FLG, 40)
head(pred, 40)
nnetFit <- fit
save(nnetFit, file='../trained_models_nnet.RData')
setwd('/Users/ivanliu/Downloads/kaggle/Coupon-Purchase-Prediction')
rm(list=ls());gc()
load('../data/2_model_based_train_test_drop_new.RData')
### split train-validation
library(caret)
set.seed(888)
inTraining <- createDataPartition(train$PURCHASE_FLG, p = .75, list = FALSE)
validation <- train[-inTraining,]
training <- train[inTraining,]
dim(validation);dim(training)
object.size(training)/1024/1024/1024
rm(test,train, inTraining, dropout, newregister)
### modeling
# library(doMC)
# registerDoMC(cores = 2)
training$PURCHASE_FLG <- as.factor(training$PURCHASE_FLG)
levels(training$PURCHASE_FLG) <- c('No','Yes')
# model settings
fitControl <- trainControl(method = "none", # adaptive_cv
number = 10, #10
#                            repeats = 1, #5
classProbs = TRUE,
summaryFunction = twoClassSummary,
# allowParallel = TRUE,
selectionFunction = 'best'#,
#                            adaptive = list(min = 4, #10
#                                            alpha = 0.05,
#                                            method = "BT",
#                                            complete = TRUE)
)
# grid
# Grid <-  expand.grid(interaction.depth = 6,
#                      n.trees = 300,
#                      shrinkage = 0.01#,
#                      #n.minobsinnode = 20
# )
# Grid <- expand.grid(mtry = 17) #rf
# Grid <- expand.grid(size = 6, decay = 0.5) #nnet
Grid <- expand.grid(fL = 1, usekernel = T) #nb
# Grid <- expand.grid(nIter = 100) #LogitBoost
# train
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "nb",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
# tuneLength = 6, #8
verbose = TRUE,
tuneGrid = Grid,
metric = "ROC")
fit
warnings()
featImp <- varImp(fit, scale = FALSE)
featImp
featImp <- varImp(fit, scale = FALSE)
pred <- predict(fit, newdata = validation, type = "prob")
setwd('/Users/ivanliu/Downloads/kaggle/Coupon-Purchase-Prediction')
rm(list=ls());gc()
load('../data/2_model_based_train_test_drop_new.RData')
### split train-validation
library(caret)
set.seed(888)
inTraining <- createDataPartition(train$PURCHASE_FLG, p = .75, list = FALSE)
validation <- train[-inTraining,]
training <- train[inTraining,]
dim(validation);dim(training)
object.size(training)/1024/1024/1024
rm(test,train, inTraining, dropout, newregister)
### modeling
# library(doMC)
# registerDoMC(cores = 2)
training$PURCHASE_FLG <- as.factor(training$PURCHASE_FLG)
levels(training$PURCHASE_FLG) <- c('No','Yes')
# model settings
fitControl <- trainControl(method = "none", # adaptive_cv
number = 10, #10
#                            repeats = 1, #5
classProbs = TRUE,
summaryFunction = twoClassSummary,
# allowParallel = TRUE,
selectionFunction = 'best'#,
#                            adaptive = list(min = 4, #10
#                                            alpha = 0.05,
#                                            method = "BT",
#                                            complete = TRUE)
)
# grid
# Grid <-  expand.grid(interaction.depth = 6,
#                      n.trees = 300,
#                      shrinkage = 0.01#,
#                      #n.minobsinnode = 20
# )
# Grid <- expand.grid(mtry = 13) #rf
# Grid <- expand.grid(size = 6, decay = 0.5) #nnet
# Grid <- expand.grid(fL = 1, usekernel = T) #nb
Grid <- expand.grid(nIter = 100) #LogitBoost
# train
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "LogitBoost",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
# tuneLength = 6, #8
verbose = TRUE,
tuneGrid = Grid,
metric = "ROC")
fit
featImp <- varImp(fit, scale = FALSE)
featImp
pred <- predict(fit, newdata = validation, type = "prob")
glmFit <- fit
save(glmFit, file='../trained_models_glm.RData')
head(pred)
range(pred[,2])
setwd('/Users/ivanliu/Downloads/kaggle/Coupon-Purchase-Prediction')
rm(list=ls());gc()
load('../data/2_model_based_train_test_drop_new.RData')
### split train-validation
library(caret)
set.seed(888)
inTraining <- createDataPartition(train$PURCHASE_FLG, p = .75, list = FALSE)
validation <- train[-inTraining,]
training <- train[inTraining,]
dim(validation);dim(training)
object.size(training)/1024/1024/1024
rm(test,train, inTraining, dropout, newregister)
### modeling
# library(doMC)
# registerDoMC(cores = 2)
training$PURCHASE_FLG <- as.factor(training$PURCHASE_FLG)
levels(training$PURCHASE_FLG) <- c('No','Yes')
# model settings
fitControl <- trainControl(method = "adaptive_cv", # adaptive_cv
number = 10, #10
#                            repeats = 1, #5
classProbs = TRUE,
summaryFunction = twoClassSummary,
# allowParallel = TRUE,
selectionFunction = 'best'#,
adaptive = list(min = 6, #10
alpha = 0.05,
method = "BT",
complete = TRUE)
)
# grid
# Grid <-  expand.grid(interaction.depth = 6,
#                      n.trees = 300,
#                      shrinkage = 0.01#,
#                      #n.minobsinnode = 20
# )
# Grid <- expand.grid(mtry = 13) #rf
# Grid <- expand.grid(size = 6, decay = 0.5) #nnet
# Grid <- expand.grid(fL = 1, usekernel = T) #nb
Grid <- expand.grid(nIter = 100) #LogitBoost
# train
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "LogitBoost",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
tuneLength = 6, #8
verbose = TRUE,
# tuneGrid = Grid,
metric = "ROC")
# model settings
fitControl <- trainControl(method = "adaptive_cv", # adaptive_cv
number = 10, #10
#                            repeats = 1, #5
classProbs = TRUE,
summaryFunction = twoClassSummary,
# allowParallel = TRUE,
selectionFunction = 'best',
adaptive = list(min = 6, #10
alpha = 0.05,
method = "BT",
complete = TRUE)
)
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "LogitBoost",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
tuneLength = 6, #8
verbose = TRUE,
# tuneGrid = Grid,
metric = "ROC")
fit
setwd('/Users/ivanliu/Downloads/kaggle/Coupon-Purchase-Prediction')
rm(list=ls());gc()
load('../data/2_model_based_train_test_drop_new.RData')
### split train-validation
library(caret)
set.seed(888)
inTraining <- createDataPartition(train$PURCHASE_FLG, p = .75, list = FALSE)
validation <- train[-inTraining,]
training <- train[inTraining,]
dim(validation);dim(training)
object.size(training)/1024/1024/1024
rm(test,train, inTraining, dropout, newregister)
### modeling
# library(doMC)
# registerDoMC(cores = 2)
training$PURCHASE_FLG <- as.factor(training$PURCHASE_FLG)
levels(training$PURCHASE_FLG) <- c('No','Yes')
# model settings
fitControl <- trainControl(method = "adaptive_cv", # adaptive_cv
number = 10, #10
#                            repeats = 1, #5
classProbs = TRUE,
summaryFunction = twoClassSummary,
# allowParallel = TRUE,
selectionFunction = 'best',
adaptive = list(min = 6, #10
alpha = 0.05,
method = "BT",
complete = TRUE)
)
# grid
# Grid <-  expand.grid(interaction.depth = 6,
#                      n.trees = 300,
#                      shrinkage = 0.01#,
#                      #n.minobsinnode = 20
# )
# Grid <- expand.grid(mtry = 13) #rf
# Grid <- expand.grid(size = 6, decay = 0.5) #nnet
# Grid <- expand.grid(fL = 1, usekernel = T) #nb
# Grid <- expand.grid(nIter = 60) #LogitBoost
# train
set.seed(8)
fit <- train(PURCHASE_FLG ~ .,
data = training[,-c(1,2)],
method = "rf",
trControl = fitControl,
# preProc = c("pca"), #"center", "scale"
tuneLength = 6, #8
verbose = TRUE,
# tuneGrid = Grid,
metric = "ROC")
